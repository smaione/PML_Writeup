---
title: "Human Activity Recognition"
author: "smaione"
output: html_document
---


## Get the Data

The caret package is necessary for partitioning data and the ML algorithms used in this project.
```{r, results="hide"}
rm(list=ls()); par(mfrow=c(1, 1))
library(caret)
```

The sample and hold-out data sets are downloaded to the working directory and read to the "in\_sample" and "out\_sample" data frames.
```{r, cache=TRUE}

trainURL <- paste("http://d396qusza40orc.cloudfront.net",
                  "/predmachlearn/pml-training.csv", sep="")
testURL <- paste("http://d396qusza40orc.cloudfront.net",
                 "/predmachlearn/pml-testing.csv", sep="")

download.file(trainURL, "./pml-training.csv")
download.file(testURL, "./pml-testing.csv")

in_sample <- read.csv("./pml-training.csv", na.strings=c("", "NA", "#DIV/0!"))
out_sample <- read.csv("./pml-testing.csv", na.strings=c("", "NA", "#DIV/0!"))
```


## Preprocess

Variables that don't provide any information, such as IDs, are removed as well as those containing NAs.
```{r, cache=FALSE}
# remove first seven columns from each dataset
in_sample <- in_sample[, -1:-7]
out_sample <- out_sample[, -1:-7]

# remove ID variable
out_sample <- out_sample[, -160]

# remove any variables that may have missing data
num_NAs <- apply(in_sample, 2, function(x) { sum(is.na(x)) } )
in_sample <- in_sample[, which(num_NAs == 0)]
out_sample <- out_sample[, which(num_NAs == 0)]
```

The in\_sample data is partitioned into training and test sets with a 7:3 ratio respectively.
```{r, cache=FALSE}
inTrain <- createDataPartition(y=in_sample$classe, p=0.7, list=F)
train_data <- in_sample[inTrain, ]
test_data <- in_sample[-inTrain, ]
```

## Build Model

Two models are built for comparison.  The first involves a single tree and the next a forest.  3-fold cross validation is used in each case.
```{r, results="hide"}
tree <- train(classe ~ ., method='rpart', data=train_data,
              trControl=trainControl(method='cv', number=3))

forest <- train(classe ~ ., method='rf', data=train_data,
                trControl=trainControl(method='cv', number=3))
```


## Estimate the Accuracy

The accuracies are calculated by dividing the number of correct predictions by the total number of predictions.  The tree's accuracy is followed by the forest's.
```{r, cache=FALSE}
answers <- predict(tree, test_data)
sum(answers == test_data$classe) / nrow(test_data)

answers <- predict(forest, test_data)
sum(answers == test_data$classe) / nrow(test_data)
```


## Test Prediction

With the confidence that a random forest is the superior model, the final forest is built from the entire training sample that was downloaded at the start rather than just the 70% partition.
```{r, cache=FALSE}
forest <- train(classe ~ ., method='rf', data=in_sample,
                trControl=trainControl(method='cv', number=3))
```

The final predictions are now made on the out of sample data.
```{r, cache=FALSE}
(submissions <- predict(forest, out_sample))
```

Each out of sample prediction is written to a separate text file.
```{r, cache=FALSE}
pml_write_files = function(x) {
    n = length(x)
    for (i in 1:n) {
        filename <- paste0("problem_id_",i,".txt")
        write.table(x[i], file=filename, quote=F, row.names=F, col.names=F)
    }
}

setwd("Submissions/")
pml_write_files(submissions)
```
